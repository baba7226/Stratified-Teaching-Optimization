{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4eccdc9b",
   "metadata": {},
   "source": [
    "该代码的主要功能是从两个Excel文件中的多页数据表汇中提取学生信息，进行数据清洗与合并，并将处理后的数据保存为新的Excel文件，便于后续分析。以下是对代码的简要解释：\n",
    "\n",
    "1. **模糊匹配函数（fuzzy_match_column）**\n",
    "   用于模糊匹配字段名称，找到与目标字段最接近的列名。\n",
    "\n",
    "2. **字段提取函数（extract_fields_from_excel）**\n",
    "   从Excel文件中提取指定字段，先进行精确匹配，模糊匹配作为备选，并处理字段名称中的空格和学号字段的格式问题。返回清洗后的DataFrame。\n",
    "\n",
    "3. **字段映射定义**\n",
    "   定义了字段映射关系：\n",
    "\n",
    "* `fields_file1`：从第一个Excel文件中提取的字段映射。\n",
    "* `fields_file2`：从第二个Excel文件中提取的字段映射。\n",
    "\n",
    "4. **数据提取与清洗**\n",
    "   使用`extract_fields_from_excel`函数分别从`file1`和`file2`中提取并清洗数据，生成`df1`和`df2`。\n",
    "\n",
    "5. **数据合并**\n",
    "   使用`pd.merge`函数根据学号（`xuehao`）将两个DataFrame合并，保留在两个文件中都存在的记录。\n",
    "\n",
    "6. **学院一致性检查**\n",
    "   检查合并后的学院字段（`yuanxi_x`和`yuanxi_y`）是否一致，若不一致，输出警告并保留一个`yuanxi`列。\n",
    "\n",
    "7. **保存合并结果**\n",
    "   将合并后的数据保存为新的Excel文件。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e714bd-d51a-41d6-8d0e-a29c63f70a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📄 正在处理文件：C:\\Users\\31258\\Desktop\\新版\\原数据\\24级数据\\【1-2】2024级新生分层数据汇总表 -全校挂牌.xls\n",
      "✅ 字段精确匹配：学号 → 学号\n",
      "✅ 字段精确匹配：xymc → xymc\n",
      "✅ 字段精确匹配：姓名 → 姓名\n",
      "✅ 字段精确匹配：高考数学规格化成绩80+(X-各类试卷均分)*折合系数 → 高考数学规格化成绩80+(X-各类试卷均分)*折合系数\n",
      "✅ 字段精确匹配：入学测成绩 → 入学测成绩\n",
      "✅ 字段精确匹配：切屏次数 → 切屏次数\n",
      "✅ 字段精确匹配：综合成绩(高考规格化成绩*0.7+入学测成绩*0.3) → 综合成绩(高考规格化成绩*0.7+入学测成绩*0.3)\n",
      "⚠️ 字段模糊匹配：建议分层 → 分层\n",
      "\n",
      "📄 正在处理文件：C:\\Users\\31258\\Desktop\\新版\\原数据\\24级数据\\【2-3】24-25(1)三次成绩汇总.xlsx\n",
      "✅ 字段精确匹配：学号 → 学号\n",
      "✅ 字段精确匹配：学院（必须填写） → 学院（必须填写）\n",
      "⚠️ 字段模糊匹配：阶测1 → 阶测1成绩\n",
      "⚠️ 字段模糊匹配：阶测2 → 阶测2成绩\n",
      "⚠️ 字段模糊匹配：期末 → 期末成绩\n",
      "\n",
      "⚠️ 学号存在学院不一致情况：\n",
      "            xuehao yuanxi_x    yuanxi_y\n",
      "890   202483270165     长望学院   电子与信息工程学院\n",
      "891   202483270165     长望学院   电子与信息工程学院\n",
      "930   202483270070     长望学院   电子与信息工程学院\n",
      "931   202483270070     长望学院   电子与信息工程学院\n",
      "1216  202413930097     长望学院       自动化学院\n",
      "...            ...      ...         ...\n",
      "6174  202483270143   管理工程学院  电子与信息工程 学院\n",
      "6175  202483270143   管理工程学院  电子与信息工程 学院\n",
      "6252  202483390047  化学与材料学院      管理工程学院\n",
      "6269  202483270519      商学院   电子与信息工程学院\n",
      "6274  202413930089      商学院       自动化学院\n",
      "\n",
      "[249 rows x 3 columns]\n",
      "\n",
      "✅ 合并成功，最终记录数：6276 条\n",
      "📄 合并结果保存至：C:\\Users\\31258\\Desktop\\新版\\数据整合以及清洗\\24级\\24级学生整合成绩表.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import difflib\n",
    "import os\n",
    "\n",
    "# === 路径设置 ===\n",
    "base_path = r'C:\\Users\\31258\\Desktop\\新版\\原数据\\24级数据'\n",
    "file1 = os.path.join(base_path, '【1-2】2024级新生分层数据汇总表 -全校挂牌.xls')\n",
    "file2 = os.path.join(base_path, '【2-3】24-25(1)三次成绩汇总.xlsx')\n",
    "output_path = r'C:\\Users\\31258\\Desktop\\新版\\数据整合以及清洗\\24级\\24级学生整合成绩表.xlsx'\n",
    "\n",
    "# === 模糊匹配函数（备选） ===\n",
    "def fuzzy_match_column(keyword, columns):\n",
    "    match = difflib.get_close_matches(keyword, columns, n=1, cutoff=0.3)\n",
    "    return match[0] if match else None\n",
    "\n",
    "# === 字段提取函数（优先精确匹配） ===\n",
    "def extract_fields_from_excel(file_path, field_map):\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    all_data = pd.concat([xls.parse(sheet) for sheet in xls.sheet_names], ignore_index=True)\n",
    "\n",
    "    all_data.columns = all_data.columns.astype(str).str.replace(r'\\s+', '', regex=True)\n",
    "    matched = {}\n",
    "    used_columns = set()\n",
    "\n",
    "    print(f\"\\n📄 正在处理文件：{file_path}\")\n",
    "    for zh, en in field_map.items():\n",
    "        # 精确匹配\n",
    "        exact_match = [col for col in all_data.columns if zh.replace(\" \", \"\") == col]\n",
    "        if exact_match:\n",
    "            matched[en] = exact_match[0]\n",
    "            used_columns.add(exact_match[0])\n",
    "            print(f\"✅ 字段精确匹配：{zh} → {exact_match[0]}\")\n",
    "        else:\n",
    "            # 模糊匹配（备选）\n",
    "            available_columns = [col for col in all_data.columns if col not in used_columns]\n",
    "            fuzzy_match = fuzzy_match_column(zh, available_columns)\n",
    "            if fuzzy_match:\n",
    "                matched[en] = fuzzy_match\n",
    "                used_columns.add(fuzzy_match)\n",
    "                print(f\"⚠️ 字段模糊匹配：{zh} → {fuzzy_match}\")\n",
    "            else:\n",
    "                print(f\"❌ 未找到字段: {zh}\")\n",
    "\n",
    "    df = all_data[[matched[k] for k in matched]].copy()\n",
    "    df.columns = list(matched.keys())\n",
    "\n",
    "    df = df[df['xuehao'].notna()].copy()\n",
    "    df['xuehao'] = df['xuehao'].astype(str).str.strip().str.replace('.0', '', regex=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "# === 字段映射定义 ===\n",
    "fields_file1 = {\n",
    "    '学号': 'xuehao',\n",
    "    'xymc': 'yuanxi',\n",
    "    '姓名': 'xingming',\n",
    "    '高考数学规格化成绩80+(X-各类试卷均分)*折合系数': 'gaokao_math_norm',\n",
    "    '入学测成绩': 'entrance_score',\n",
    "    '切屏次数': 'entrance_bclass',  # ✅ 修改为实际列名\n",
    "    '综合成绩(高考规格化成绩*0.7+入学测成绩*0.3)': 'total_score',\n",
    "    '建议分层': 'layer_advice'\n",
    "}\n",
    "\n",
    "fields_file2 = {\n",
    "    '学号': 'xuehao',\n",
    "    '学院（必须填写）': 'yuanxi',\n",
    "    '阶测1': 'step1',\n",
    "    '阶测2': 'step2',\n",
    "    '期末': 'final'\n",
    "}\n",
    "\n",
    "# === 提取数据 ===\n",
    "df1 = extract_fields_from_excel(file1, fields_file1)\n",
    "df2 = extract_fields_from_excel(file2, fields_file2)\n",
    "\n",
    "# === 合并数据 ===\n",
    "merged = pd.merge(df1, df2, on='xuehao', how='inner', suffixes=('_x', '_y'))\n",
    "\n",
    "# === 保留一个 yuanxi 列，检查一致性 ===\n",
    "if 'yuanxi_x' in merged.columns and 'yuanxi_y' in merged.columns:\n",
    "    mismatch = (merged['yuanxi_x'] != merged['yuanxi_y']) & merged['yuanxi_x'].notna() & merged['yuanxi_y'].notna()\n",
    "    if mismatch.any():\n",
    "        print(\"\\n⚠️ 学号存在学院不一致情况：\")\n",
    "        print(merged.loc[mismatch, ['xuehao', 'yuanxi_x', 'yuanxi_y']])\n",
    "    merged['yuanxi'] = merged['yuanxi_x']\n",
    "    merged.drop(['yuanxi_x', 'yuanxi_y'], axis=1, inplace=True)\n",
    "\n",
    "# === 保存合并结果 ===\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "merged.to_excel(output_path, index=False)\n",
    "\n",
    "# === 输出信息 ===\n",
    "print(f\"\\n✅ 合并成功，最终记录数：{len(merged)} 条\")\n",
    "print(f\"📄 合并结果保存至：{output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f118e11",
   "metadata": {},
   "source": [
    "该代码的核心功能是从原始数据中清洗出有效的学生成绩信息，删除不符合要求的记录，并将清洗后的数据保存为新文件。以下是对核心逻辑的说明：\n",
    "\n",
    "1. **加载数据**\n",
    "   通过`pd.read_excel()`加载原始的Excel数据，获取学生成绩的完整记录，并统计原始数据总条数。\n",
    "\n",
    "2. **确保成绩字段为数值型**\n",
    "   对`step1`、`step2`、`final`等成绩字段进行转换，确保它们为数值型数据。对于非数字或无法转换为数字的值，使用`NaN`填充。\n",
    "\n",
    "3. **删除成绩为0、空值或非数字的记录**\n",
    "   对每个成绩字段（如`gaokao_math_norm`、`entrance_score`等），删除其中成绩为0、空值或非数字的记录。删除时打印被删除记录的数量及前3条示例，确保用户了解数据处理情况。\n",
    "\n",
    "4. **删除切屏次数 ≥ 6 的记录**\n",
    "   将`entrance_bclass`字段转换为数值型，并删除切屏次数（`entrance_bclass`）大于等于6的记录。也打印出被删除的记录数量及示例，便于确认。\n",
    "\n",
    "5. **删除分层结果为空或空字符串的记录**\n",
    "   删除分层结果（`layer_advice`）为空或空字符串的记录。确保分层数据的完整性，以便后续分析。\n",
    "\n",
    "6. **结果统计与保存**\n",
    "   通过`df.reset_index()`重新索引，并计算清洗后的数据总条数。最终将清洗后的数据保存为新的Excel文件，输出处理信息，包括清洗后的记录数和删除的记录数。\n",
    "\n",
    "总结：\n",
    "此代码通过清洗操作，去除了无效的成绩记录、切屏次数过多的记录以及分层结果为空的记录，保证了数据的质量，最终生成了一个清洗后的学生成绩数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e3f0c45-8bb7-4576-8d57-95b587ebce4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 原始数据总记录数：6276 条\n",
      "🔍 删除【gaokao_math_norm】为 0 或空值的记录：62 条\n",
      "           xuehao  gaokao_math_norm\n",
      "846  202483300459               0.0\n",
      "847  202483300291               0.0\n",
      "848  202483300268               0.0\n",
      "🔍 删除【entrance_score】为 0 或空值的记录：237 条\n",
      "           xuehao  entrance_score\n",
      "750  202483300096             0.0\n",
      "800  202483300293             0.0\n",
      "803  202483300236             0.0\n",
      "🔍 删除【total_score】为 0 或空值的记录：0 条\n",
      "🔍 删除【step1】为 0 或空值的记录：13 条\n",
      "            xuehao  step1\n",
      "202   202483300689    NaN\n",
      "1092  202483450105    NaN\n",
      "1291  202483450060    NaN\n",
      "🔍 删除【step2】为 0 或空值的记录：24 条\n",
      "            xuehao  step2\n",
      "214   202483300231    NaN\n",
      "376   202483300306    NaN\n",
      "1004  202483230036    NaN\n",
      "🔍 删除【final】为 0 或空值的记录：9 条\n",
      "            xuehao  final\n",
      "98    202483300653    NaN\n",
      "1633  202483230032    NaN\n",
      "1910  202483290035    NaN\n",
      "🔍 删除切屏次数 ≥ 6 的记录：315 条\n",
      "           xuehao  entrance_bclass\n",
      "377  202483300798               13\n",
      "378  202483300433                6\n",
      "379  202483300479               13\n",
      "🔍 删除分层结果为空的记录：2036 条\n",
      "           xuehao layer_advice\n",
      "873  202483670081          NaN\n",
      "874  202483750013          NaN\n",
      "875  202413020034          NaN\n",
      "\n",
      "✅ 清洗完成！剩余记录数：3580 条（共删除 2696 条）\n",
      "📄 清洗后的文件已保存至：C:\\Users\\31258\\Desktop\\新版\\数据整合以及清洗\\24级\\24级学生整合成绩表_清洗后.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === 文件路径设置 ===\n",
    "file_path = r'C:\\Users\\31258\\Desktop\\新版\\数据整合以及清洗\\24级\\24级学生整合成绩表.xlsx'\n",
    "output_path = r'C:\\Users\\31258\\Desktop\\新版\\数据整合以及清洗\\24级\\24级学生整合成绩表_清洗后.xlsx'\n",
    "\n",
    "# === 加载原始数据 ===\n",
    "df = pd.read_excel(file_path)\n",
    "original_count = len(df)\n",
    "\n",
    "print(f\"📥 原始数据总记录数：{original_count} 条\")\n",
    "\n",
    "# === 成绩字段定义 ===\n",
    "score_cols = ['gaokao_math_norm', 'entrance_score', 'total_score', 'step1', 'step2', 'final']\n",
    "\n",
    "# === 确保 step1、step2、final 为数值型（非数字转 NaN）===\n",
    "for col in ['step1', 'step2', 'final']:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# === 步骤 1：删除成绩字段为 0、空值或非数字 的行 ===\n",
    "for col in score_cols:\n",
    "    before = len(df)\n",
    "    condition = df[col].isna() | (df[col] == 0)\n",
    "    removed = df[condition]\n",
    "    df = df[~condition]\n",
    "    print(f\"🔍 删除【{col}】为 0 或空值的记录：{len(removed)} 条\")\n",
    "    if not removed.empty:\n",
    "        print(removed[['xuehao', col]].head(3))  # 打印前3条示例\n",
    "\n",
    "# === 步骤 2：删除切屏次数 ≥ 6 的行 ===\n",
    "df['entrance_bclass'] = pd.to_numeric(df['entrance_bclass'], errors='coerce')\n",
    "condition = df['entrance_bclass'] >= 6\n",
    "removed = df[condition]\n",
    "df = df[~condition]\n",
    "print(f\"🔍 删除切屏次数 ≥ 6 的记录：{len(removed)} 条\")\n",
    "if not removed.empty:\n",
    "    print(removed[['xuehao', 'entrance_bclass']].head(3))\n",
    "\n",
    "# === 步骤 3：删除分层结果 layer_advice 为空 或 空字符串 的行 ===\n",
    "condition = df['layer_advice'].isna() | (df['layer_advice'].astype(str).str.strip() == '')\n",
    "removed = df[condition]\n",
    "df = df[~condition]\n",
    "print(f\"🔍 删除分层结果为空的记录：{len(removed)} 条\")\n",
    "if not removed.empty:\n",
    "    print(removed[['xuehao', 'layer_advice']].head(3))\n",
    "\n",
    "# === 结果统计 ===\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "final_count = len(df)\n",
    "print(f\"\\n✅ 清洗完成！剩余记录数：{final_count} 条（共删除 {original_count - final_count} 条）\")\n",
    "\n",
    "# === 保存清洗结果 ===\n",
    "df.to_excel(output_path, index=False)\n",
    "print(f\"📄 清洗后的文件已保存至：{output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1131c1c",
   "metadata": {},
   "source": [
    "根据合并、清洗好的数据，进行随机抽样调查。将'自动化学院', '龙山书院', '电子与信息工程学院'三个学院中全部的学生数据分别拆分到三个Excel表文件中，用于后续的分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0aca9120-7823-45f7-a333-abbc62b4e7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已保存：自动化学院（612 条记录） → C:\\Users\\31258\\Desktop\\新版\\数据整合以及清洗\\24级\\按院系拆分\\自动化学院_成绩表.xlsx\n",
      "✅ 已保存：龙山书院（792 条记录） → C:\\Users\\31258\\Desktop\\新版\\数据整合以及清洗\\24级\\按院系拆分\\龙山书院_成绩表.xlsx\n",
      "✅ 已保存：电子与信息工程学院（726 条记录） → C:\\Users\\31258\\Desktop\\新版\\数据整合以及清洗\\24级\\按院系拆分\\电子与信息工程学院_成绩表.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ✅ 已清洗后的 Excel 文件路径（根据实际路径修改）\n",
    "cleaned_file_path = r'C:\\Users\\31258\\Desktop\\新版\\数据整合以及清洗\\24级\\24级学生整合成绩表_清洗后.xlsx'\n",
    "\n",
    "# ✅ 加载数据\n",
    "df_cleaned = pd.read_excel(cleaned_file_path)\n",
    "\n",
    "# ✅ 要提取的目标院系列表\n",
    "target_departments = ['自动化学院', '龙山书院', '电子与信息工程学院']\n",
    "\n",
    "# ✅ 院系列字段名（如果你的列名不是 'yuanxi' 请替换）\n",
    "department_col = 'yuanxi'\n",
    "\n",
    "# ✅ 保存目录（与源文件同目录）\n",
    "output_dir = os.path.join(os.path.dirname(cleaned_file_path), '按院系拆分')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ✅ 遍历每个院系并保存\n",
    "for dept in target_departments:\n",
    "    dept_df = df_cleaned[df_cleaned[department_col] == dept]\n",
    "\n",
    "    if not dept_df.empty:\n",
    "        save_path = os.path.join(output_dir, f'{dept}_成绩表.xlsx')\n",
    "        dept_df.to_excel(save_path, index=False)\n",
    "        print(f'✅ 已保存：{dept}（{len(dept_df)} 条记录） → {save_path}')\n",
    "    else:\n",
    "        print(f'⚠️ 未找到数据：{dept}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5077bbfa",
   "metadata": {},
   "source": [
    "# 代码功能总结\n",
    "\n",
    "这段代码主要实现了对抽取出来的三个院系的学生成绩数据进行相关性分析，并生成相关性分析报告和可视化图表。具体过程如下：\n",
    "\n",
    "1. **数据加载与院系分表读取**  \n",
    "   代码首先从指定路径读取清洗后的学生成绩数据，并自动查找每个院系的成绩表。对于每个院系的数据，都会单独进行分析。\n",
    "\n",
    "2. **相关性分析**  \n",
    "   代码定义了多个字段对，进行皮尔逊相关性分析，计算各个字段之间的相关系数和p值。分析的字段包括高考数学规范化成绩、入学测成绩、阶段性成绩（1和2）和期末成绩。\n",
    "\n",
    "3. **结果记录与输出**  \n",
    "   对每个院系，代码会计算相关系数和p值，并根据p值判断相关性是否显著。如果样本数据不足，标记为“样本过少”。分析结果会被存储到一个Excel报告中，并同时为每个相关性字段对生成对应的散点图。\n",
    "\n",
    "4. **图表保存**  \n",
    "   相关性分析结果通过`seaborn`绘制散点图和回归线，并将图表保存在指定的文件夹中，确保每个图表的文件名合法。\n",
    "\n",
    "最终，代码完成后会输出分析完成的提示，报告和图表被保存在指定的输出目录，方便用户查看和分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "998c1b80-936b-472c-bba7-c3d58b59c85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 分析完成\n",
      "📄 报告已保存至： C:\\Users\\31258\\Desktop\\新版\\分析\\24级\\相关性\\相关性分析报告.xlsx\n",
      "🖼️ 图表保存目录： C:\\Users\\31258\\Desktop\\新版\\分析\\24级\\相关性\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib\n",
    "\n",
    "# === 设置 matplotlib 中文支持 ===\n",
    "matplotlib.rcParams['font.sans-serif'] = ['SimHei']\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# === 路径设置 ===\n",
    "base_path = r'C:\\Users\\31258\\Desktop\\新版\\数据整合以及清洗\\24级'\n",
    "input_path = os.path.join(base_path, '24级学生整合成绩表_清洗后.xlsx')\n",
    "\n",
    "# 院系分表路径（自动查找）\n",
    "dept_dir = os.path.join(base_path, '按院系拆分')\n",
    "\n",
    "# 输出结果目录\n",
    "output_dir = r'C:\\Users\\31258\\Desktop\\新版\\分析\\24级\\相关性'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# === 读取总数据 ===\n",
    "df_all = pd.read_excel(input_path)\n",
    "\n",
    "# === 院系字段名 ===\n",
    "department_col = 'yuanxi'\n",
    "\n",
    "# === 自动化读取部门文件 ===\n",
    "target_departments = ['自动化学院', '龙山书院', '电子与信息工程学院']\n",
    "departments = {'全体': df_all}\n",
    "\n",
    "for dept in target_departments:\n",
    "    dept_file = os.path.join(dept_dir, f'{dept}_成绩表.xlsx')\n",
    "    if os.path.exists(dept_file):\n",
    "        departments[dept] = pd.read_excel(dept_file)\n",
    "    else:\n",
    "        print(f'⚠️ 未找到文件: {dept_file}')\n",
    "\n",
    "# === 要分析的字段对 ===\n",
    "correlation_pairs = [\n",
    "    ('gaokao_math_norm', 'entrance_score'),\n",
    "    ('step1', 'step2'),\n",
    "    ('step1', 'final'),\n",
    "    ('step2', 'final')\n",
    "]\n",
    "\n",
    "# === 存储所有分析结果 ===\n",
    "results_all = []\n",
    "\n",
    "# === 分析函数 ===\n",
    "def analyze_and_plot(df, dept_name):\n",
    "    for x_col, y_col in correlation_pairs:\n",
    "        data = df[[x_col, y_col]].dropna()\n",
    "        if len(data) < 3:\n",
    "            results_all.append({\n",
    "                '院系': dept_name,\n",
    "                '变量1': x_col,\n",
    "                '变量2': y_col,\n",
    "                '样本数': len(data),\n",
    "                '相关系数 r': None,\n",
    "                'p 值': None,\n",
    "                '备注': '样本过少'\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        r, p = pearsonr(data[x_col], data[y_col])\n",
    "        results_all.append({\n",
    "            '院系': dept_name,\n",
    "            '变量1': x_col,\n",
    "            '变量2': y_col,\n",
    "            '样本数': len(data),\n",
    "            '相关系数 r': round(r, 4),\n",
    "            'p 值': format(p, '.4g'),\n",
    "            '备注': '显著' if p < 0.05 else '不显著'\n",
    "        })\n",
    "\n",
    "        # 绘图\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.regplot(x=x_col, y=y_col, data=data, line_kws={\"color\": \"red\"})\n",
    "        plt.title(f'{dept_name}: {x_col} vs {y_col}\\nr = {r:.4f}, p = {p:.4g}')\n",
    "        plt.xlabel(x_col)\n",
    "        plt.ylabel(y_col)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # 合法文件名\n",
    "        safe_name = f\"{dept_name}_{x_col}_vs_{y_col}\".replace(\":\", \"\").replace(\"/\", \"_\")\n",
    "        plt.savefig(os.path.join(output_dir, f\"{safe_name}.png\"))\n",
    "        plt.close()\n",
    "\n",
    "# === 执行分析 ===\n",
    "for dept_name, df in departments.items():\n",
    "    analyze_and_plot(df, dept_name)\n",
    "\n",
    "# === 保存分析结果 ===\n",
    "results_df = pd.DataFrame(results_all)\n",
    "excel_output = os.path.join(output_dir, '相关性分析报告.xlsx')\n",
    "results_df.to_excel(excel_output, index=False)\n",
    "\n",
    "# === 完成提示 ===\n",
    "print(\"✅ 分析完成\")\n",
    "print(\"📄 报告已保存至：\", excel_output)\n",
    "print(\"🖼️ 图表保存目录：\", output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2771fdb4",
   "metadata": {},
   "source": [
    "这段代码的主要作用是针对不同院系的学生成绩数据，进行分层均值检验（t检验），分析不同分层（A层与B层）之间在各个成绩字段（如step1, step2, final）上的差异，且根据检验结果生成柱状图和箱线图，最终保存分析结果和图表。（经分析后这个结果有问题，问题来源于数据清洗的规则）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0aa82186-c627-4778-9c2c-16c36ce4cb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 所有院系均值检验与图表保存完成\n",
      "📊 检验表格： C:\\Users\\31258\\Desktop\\新版\\分析\\24级\\分层均值检验\\分层均值检验结果.xlsx\n",
      "🖼️ 图表文件夹： C:\\Users\\31258\\Desktop\\新版\\分析\\24级\\分层均值检验\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import ttest_ind\n",
    "import matplotlib\n",
    "\n",
    "# ✅ 设置中文字体支持\n",
    "matplotlib.rcParams['font.sans-serif'] = ['SimHei']\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# === 分析字段 ===\n",
    "test_columns = ['step1', 'step2', 'final']\n",
    "layer_col = 'layer_advice'\n",
    "\n",
    "# === 数据路径（清洗后的24级） ===\n",
    "data_path = r'C:\\Users\\31258\\Desktop\\新版\\数据整合以及清洗\\24级\\24级学生整合成绩表_清洗后.xlsx'\n",
    "df_all = pd.read_excel(data_path)\n",
    "\n",
    "# === 院系字段 ===\n",
    "department_col = 'yuanxi'\n",
    "departments = {\n",
    "    '全体': df_all,\n",
    "    '自动化学院': df_all[df_all[department_col] == '自动化学院'],\n",
    "    '龙山书院': df_all[df_all[department_col] == '龙山书院'],\n",
    "    '电子与信息工程学院': df_all[df_all[department_col] == '电子与信息工程学院']\n",
    "}\n",
    "\n",
    "# === 输出路径 ===\n",
    "base_output_dir = r'C:\\Users\\31258\\Desktop\\新版\\分析\\24级\\分层均值检验'\n",
    "os.makedirs(base_output_dir, exist_ok=True)\n",
    "\n",
    "# === 存放 t 检验结果 ===\n",
    "t_results = []\n",
    "\n",
    "# === 分析函数 ===\n",
    "def test_layer_and_plot(df, dept_name):\n",
    "    dept_dir = os.path.join(base_output_dir, dept_name)\n",
    "    os.makedirs(dept_dir, exist_ok=True)\n",
    "\n",
    "    for col in test_columns:\n",
    "        sub = df[[col, layer_col]].dropna()\n",
    "\n",
    "        if sub[layer_col].nunique() < 2:\n",
    "            t_results.append({\n",
    "                '院系': dept_name,\n",
    "                '变量': col,\n",
    "                'A层均值': None,\n",
    "                'B层均值': None,\n",
    "                'p值': None,\n",
    "                '结论': '无A/B层或数据不足'\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        A = sub[sub[layer_col] == 'A'][col]\n",
    "        B = sub[sub[layer_col] == 'B'][col]\n",
    "\n",
    "        if len(A) < 2 or len(B) < 2:\n",
    "            t_results.append({\n",
    "                '院系': dept_name,\n",
    "                '变量': col,\n",
    "                'A层均值': A.mean() if len(A) > 0 else None,\n",
    "                'B层均值': B.mean() if len(B) > 0 else None,\n",
    "                'p值': None,\n",
    "                '结论': '样本数不足'\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # ✅ t检验：A > B 是否显著\n",
    "        t_stat, p_val = ttest_ind(A, B, equal_var=False, alternative='greater')\n",
    "        t_results.append({\n",
    "            '院系': dept_name,\n",
    "            '变量': col,\n",
    "            'A层均值': round(A.mean(), 2),\n",
    "            'B层均值': round(B.mean(), 2),\n",
    "            'p值': format(p_val, '.4g'),\n",
    "            '结论': 'A显著高于B' if p_val < 0.05 else '差异不显著'\n",
    "        })\n",
    "\n",
    "        # ✅ 柱状图\n",
    "        plt.figure(figsize=(5, 4))\n",
    "        sns.barplot(data=sub, x=layer_col, y=col, hue=layer_col, errorbar='sd', palette='pastel', legend=False)\n",
    "        plt.title(f'{dept_name}：{col} 平均成绩对比（A vs B）')\n",
    "        plt.xlabel(\"分层\")\n",
    "        plt.ylabel(col)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(dept_dir, f'{col}_bar.png'))\n",
    "        plt.close()\n",
    "\n",
    "        # ✅ 箱线图\n",
    "        plt.figure(figsize=(5, 4))\n",
    "        sns.boxplot(data=sub, x=layer_col, y=col, hue=layer_col, palette='Set2', legend=False)\n",
    "        plt.title(f'{dept_name}：{col} 成绩分布（箱线图）')\n",
    "        plt.xlabel(\"分层\")\n",
    "        plt.ylabel(col)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(dept_dir, f'{col}_box.png'))\n",
    "        plt.close()\n",
    "\n",
    "# === 执行所有院系分析 ===\n",
    "for dept, df in departments.items():\n",
    "    test_layer_and_plot(df, dept)\n",
    "\n",
    "# === 保存最终检验结果表 ===\n",
    "output_file = os.path.join(base_output_dir, '分层均值检验结果.xlsx')\n",
    "pd.DataFrame(t_results).to_excel(output_file, index=False)\n",
    "\n",
    "# === 提示信息 ===\n",
    "print(\"✅ 所有院系均值检验与图表保存完成\")\n",
    "print(\"📊 检验表格：\", output_file)\n",
    "print(\"🖼️ 图表文件夹：\", base_output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943f5150",
   "metadata": {},
   "source": [
    "# 数据清洗规则（新）\n",
    "\n",
    "以下是根据上一个分层均值检验中问题进行分析，重新构建的数据清洗过程的规则：\n",
    "\n",
    "1. **字段选择**  \n",
    "   只保留必要的字段：`xuehao`, `yuanxi`, `step1`, `step2`, `final`, `layer_advice`，其余不相关的字段被剔除，减少数据量，确保只处理所需信息。\n",
    "\n",
    "2. **数值转换**  \n",
    "   将成绩字段（`step1`, `step2`, `final`）转换为数值型。如果这些字段中的值无法转换为数值（例如包含文本或空值），则会被替换为 `NaN`。这保证了数据的统一性，排除无效字段。\n",
    "\n",
    "3. **异常成绩过滤**  \n",
    "   删除成绩小于 0 或大于 100 的记录。因为学生成绩通常应在此范围内，任何超出此范围的值被视为异常数据，因此会被移除，确保数据合理性。\n",
    "\n",
    "4. **删除空的分层结果**  \n",
    "   删除 `layer_advice`（分层结果）为空或仅包含空格的记录。通过 `notna()` 检查非 `NaN` 值，并通过 `str.strip()` 去除字符串的空格，确保仅保留有效的分层信息。\n",
    "\n",
    "5. **索引重置**  \n",
    "   在删除无效记录后，重置数据的索引。使用 `reset_index(drop=True, inplace=True)` 重新编号，使数据的索引从 0 开始，并丢弃旧的索引。\n",
    "\n",
    "6. **保存清洗后的数据**  \n",
    "   将清洗后的数据保存到新的Excel文件中，便于后续处理和分析，并输出清洗后的记录数和保存路径。\n",
    "\n",
    "这些规则帮助确保数据质量、提高数据一致性，为后续的数据分析做好准备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "364bc032-d560-4228-a29a-be3e7d2cf101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 读取成功，共 6276 条记录\n",
      "✅ 清洗完成，共保留 3965 条记录\n",
      "📄 文件已保存至：C:\\Users\\31258\\Desktop\\新版\\数据整合以及清洗\\24级\\24级学生整合成绩_分层检验用数据.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# === 文件路径设置 ===\n",
    "base_dir = r'C:\\Users\\31258\\Desktop\\新版\\数据整合以及清洗\\24级'\n",
    "input_file = os.path.join(base_dir, '24级学生整合成绩表.xlsx')\n",
    "output_file = os.path.join(base_dir, '24级学生整合成绩_分层检验用数据.xlsx')\n",
    "\n",
    "# === 加载原始数据 ===\n",
    "df = pd.read_excel(input_file)\n",
    "print(f\"📥 读取成功，共 {len(df)} 条记录\")\n",
    "\n",
    "# === 提取目标字段 ===\n",
    "columns_needed = ['xuehao', 'yuanxi', 'step1', 'step2', 'final', 'layer_advice']\n",
    "df_selected = df[columns_needed].copy()\n",
    "\n",
    "# === 转换成绩字段为数值型（处理非数字）===\n",
    "for col in ['step1', 'step2', 'final']:\n",
    "    df_selected[col] = pd.to_numeric(df_selected[col], errors='coerce')\n",
    "\n",
    "# === 清洗异常成绩（小于 0 或 大于 100）===\n",
    "for col in ['step1', 'step2', 'final']:\n",
    "    df_selected = df_selected[(df_selected[col] >= 0) & (df_selected[col] <= 100)]\n",
    "\n",
    "# === 删除分层结果为空的行 ===\n",
    "df_selected = df_selected[\n",
    "    df_selected['layer_advice'].notna() &\n",
    "    (df_selected['layer_advice'].astype(str).str.strip() != '')\n",
    "]\n",
    "\n",
    "# === 重置索引 ===\n",
    "df_selected.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# === 保存清洗后的数据 ===\n",
    "df_selected.to_excel(output_file, index=False)\n",
    "print(f\"✅ 清洗完成，共保留 {len(df_selected)} 条记录\")\n",
    "print(f\"📄 文件已保存至：{output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc79b32b",
   "metadata": {},
   "source": [
    "随机抽样，抽取三个学院（'自动化学院', '龙山书院', '计算机学院'）的数据进行分层均值检验，验证分班的科学性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e2f789e-19bb-40cb-a32b-0bc15b1601f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已保存：自动化学院（651 条记录） → C:\\Users\\31258\\Desktop\\新版\\数据整合以及清洗\\24级\\按院系拆分\\自动化学院_成绩表.xlsx\n",
      "✅ 已保存：龙山书院（869 条记录） → C:\\Users\\31258\\Desktop\\新版\\数据整合以及清洗\\24级\\按院系拆分\\龙山书院_成绩表.xlsx\n",
      "✅ 已保存：计算机学院（514 条记录） → C:\\Users\\31258\\Desktop\\新版\\数据整合以及清洗\\24级\\按院系拆分\\计算机学院_成绩表.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ✅ 已清洗后的 Excel 文件路径（根据实际路径修改）\n",
    "cleaned_file_path = r'C:\\Users\\31258\\Desktop\\新版\\数据整合以及清洗\\24级\\24级学生整合成绩_分层检验用数据.xlsx'\n",
    "\n",
    "# ✅ 加载数据\n",
    "df_cleaned = pd.read_excel(cleaned_file_path)\n",
    "\n",
    "# ✅ 要提取的目标院系列表\n",
    "target_departments = ['自动化学院', '龙山书院', '计算机学院']\n",
    "\n",
    "# ✅ 院系列字段名（如果你的列名不是 'yuanxi' 请替换）\n",
    "department_col = 'yuanxi'\n",
    "\n",
    "# ✅ 保存目录（与源文件同目录）\n",
    "output_dir = os.path.join(os.path.dirname(cleaned_file_path), '按院系拆分')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ✅ 遍历每个院系并保存\n",
    "for dept in target_departments:\n",
    "    dept_df = df_cleaned[df_cleaned[department_col] == dept]\n",
    "\n",
    "    if not dept_df.empty:\n",
    "        save_path = os.path.join(output_dir, f'{dept}_成绩表.xlsx')\n",
    "        dept_df.to_excel(save_path, index=False)\n",
    "        print(f'✅ 已保存：{dept}（{len(dept_df)} 条记录） → {save_path}')\n",
    "    else:\n",
    "        print(f'⚠️ 未找到数据：{dept}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466c2161",
   "metadata": {},
   "source": [
    "# 代码功能总结\n",
    "\n",
    "该代码的主要功能是对全校学生以及抽取的三个院系的学生成绩数据进行分层均值检验（t检验），并生成相关的可视化图表。具体步骤如下：\n",
    "\n",
    "1. **数据加载与准备：**\n",
    "   - 读取了清洗后的学生成绩数据文件 `24级学生整合成绩_分层检验用数据.xlsx`。\n",
    "   - 提取了必要的字段，包括成绩字段 (`step1`, `step2`, `final`) 和分层字段 (`layer_advice`)。\n",
    "   - 对各院系的数据进行了分组，包括“全体”、“自动化学院”、“龙山书院”和“计算机学院”。\n",
    "\n",
    "2. **分层均值检验：**\n",
    "   - 对每个院系的数据，针对每个成绩字段（`step1`, `step2`, `final`），进行分层（A层与B层）的 t 检验。\n",
    "   - 使用 `ttest_ind` 进行独立样本 t 检验，检验A层与B层的成绩是否存在显著差异。\n",
    "   - 如果某一层的数据不足（如样本数小于2），则跳过该分析，并记录“样本数不足”。\n",
    "   - 对每个字段的检验结果（包括A层均值、B层均值、p值和结论）进行了存储。\n",
    "\n",
    "3. **数据可视化：**\n",
    "   - 对每个院系，生成了柱状图和箱线图，展示A层与B层在各个成绩字段上的均值对比及成绩分布情况。\n",
    "   - 使用 `seaborn` 绘制了具有回归线的柱状图和箱线图，图表文件保存到相应院系的文件夹中。\n",
    "\n",
    "4. **输出结果：**\n",
    "   - 将所有院系的 t 检验结果保存到 `分层均值检验结果.xlsx` 文件中，并将图表保存到指定的文件夹中。\n",
    "   - 输出了完成提示，显示检验结果文件和图表文件夹的路径。\n",
    "\n",
    "### 代码流程：\n",
    "- **数据加载：** 读取清洗后的学生成绩数据。\n",
    "- **分层均值检验：** 针对不同院系和成绩字段，进行 t 检验并生成结果。\n",
    "- **图表生成：** 为每个成绩字段生成柱状图和箱线图。\n",
    "- **结果保存：** 将检验结果保存为 Excel 文件，图表保存为图片。\n",
    "\n",
    "### 主要技术点：\n",
    "- 使用 `ttest_ind` 进行 t 检验。\n",
    "- 使用 `seaborn` 和 `matplotlib` 绘制柱状图和箱线图。\n",
    "- 使用 `pandas` 进行数据处理、清洗和保存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2a19791-45e0-4554-a7e6-bd68303e9d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 所有院系均值检验与图表保存完成\n",
      "📊 检验表格： C:\\Users\\31258\\Desktop\\新版\\分析\\24级\\分层均值检验\\分层均值检验结果.xlsx\n",
      "🖼️ 图表文件夹： C:\\Users\\31258\\Desktop\\新版\\分析\\24级\\分层均值检验\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import ttest_ind\n",
    "import matplotlib\n",
    "\n",
    "# ✅ 设置中文字体支持\n",
    "matplotlib.rcParams['font.sans-serif'] = ['SimHei']\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# === 分析字段 ===\n",
    "test_columns = ['step1', 'step2', 'final']\n",
    "layer_col = 'layer_advice'\n",
    "\n",
    "# === 数据路径（清洗后的24级） ===\n",
    "data_path = r'C:\\Users\\31258\\Desktop\\新版\\数据整合以及清洗\\24级\\24级学生整合成绩_分层检验用数据.xlsx'\n",
    "df_all = pd.read_excel(data_path)\n",
    "\n",
    "# === 院系字段 ===\n",
    "department_col = 'yuanxi'\n",
    "departments = {\n",
    "    '全体': df_all,\n",
    "    '自动化学院': df_all[df_all[department_col] == '自动化学院'],\n",
    "    '龙山书院': df_all[df_all[department_col] == '龙山书院'],\n",
    "    '计算机学院': df_all[df_all[department_col] == '计算机学院']\n",
    "}\n",
    "\n",
    "# === 输出路径 ===\n",
    "base_output_dir = r'C:\\Users\\31258\\Desktop\\新版\\分析\\24级\\分层均值检验'\n",
    "os.makedirs(base_output_dir, exist_ok=True)\n",
    "\n",
    "# === 存放 t 检验结果 ===\n",
    "t_results = []\n",
    "\n",
    "# === 分析函数 ===\n",
    "def test_layer_and_plot(df, dept_name):\n",
    "    dept_dir = os.path.join(base_output_dir, dept_name)\n",
    "    os.makedirs(dept_dir, exist_ok=True)\n",
    "\n",
    "    for col in test_columns:\n",
    "        sub = df[[col, layer_col]].dropna()\n",
    "\n",
    "        if sub[layer_col].nunique() < 2:\n",
    "            t_results.append({\n",
    "                '院系': dept_name,\n",
    "                '变量': col,\n",
    "                'A层均值': None,\n",
    "                'B层均值': None,\n",
    "                'p值': None,\n",
    "                '结论': '无A/B层或数据不足'\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        A = sub[sub[layer_col] == 'A'][col]\n",
    "        B = sub[sub[layer_col] == 'B'][col]\n",
    "\n",
    "        if len(A) < 2 or len(B) < 2:\n",
    "            t_results.append({\n",
    "                '院系': dept_name,\n",
    "                '变量': col,\n",
    "                'A层均值': A.mean() if len(A) > 0 else None,\n",
    "                'B层均值': B.mean() if len(B) > 0 else None,\n",
    "                'p值': None,\n",
    "                '结论': '样本数不足'\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # ✅ t检验：A > B 是否显著\n",
    "        t_stat, p_val = ttest_ind(A, B, equal_var=False, alternative='greater')\n",
    "        t_results.append({\n",
    "            '院系': dept_name,\n",
    "            '变量': col,\n",
    "            'A层均值': round(A.mean(), 2),\n",
    "            'B层均值': round(B.mean(), 2),\n",
    "            'p值': format(p_val, '.4g'),\n",
    "            '结论': 'A显著高于B' if p_val < 0.05 else '差异不显著'\n",
    "        })\n",
    "\n",
    "        # ✅ 柱状图\n",
    "        plt.figure(figsize=(5, 4))\n",
    "        sns.barplot(data=sub, x=layer_col, y=col, hue=layer_col, errorbar='sd', palette='pastel', legend=False)\n",
    "        plt.title(f'{dept_name}：{col} 平均成绩对比（A vs B）')\n",
    "        plt.xlabel(\"分层\")\n",
    "        plt.ylabel(col)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(dept_dir, f'{col}_bar.png'))\n",
    "        plt.close()\n",
    "\n",
    "        # ✅ 箱线图\n",
    "        plt.figure(figsize=(5, 4))\n",
    "        sns.boxplot(data=sub, x=layer_col, y=col, hue=layer_col, palette='Set2', legend=False)\n",
    "        plt.title(f'{dept_name}：{col} 成绩分布（箱线图）')\n",
    "        plt.xlabel(\"分层\")\n",
    "        plt.ylabel(col)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(dept_dir, f'{col}_box.png'))\n",
    "        plt.close()\n",
    "\n",
    "# === 执行所有院系分析 ===\n",
    "for dept, df in departments.items():\n",
    "    test_layer_and_plot(df, dept)\n",
    "\n",
    "# === 保存最终检验结果表 ===\n",
    "output_file = os.path.join(base_output_dir, '分层均值检验结果.xlsx')\n",
    "pd.DataFrame(t_results).to_excel(output_file, index=False)\n",
    "\n",
    "# === 提示信息 ===\n",
    "print(\"✅ 所有院系均值检验与图表保存完成\")\n",
    "print(\"📊 检验表格：\", output_file)\n",
    "print(\"🖼️ 图表文件夹：\", base_output_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
